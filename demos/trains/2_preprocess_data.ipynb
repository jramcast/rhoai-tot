{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46f08194-cee0-4cea-8661-ec82d9c9a5bd",
   "metadata": {},
   "source": [
    "# Preprocess Data\n",
    "\n",
    "In this case, data preprocessing stage generates synthetic data to improve model performance when training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e887d67",
   "metadata": {},
   "source": [
    "## Ensure Data is Available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d54d2f9-ee15-4a0d-9015-2a59345aebd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -rf dataset\n",
    "! tar -xzf dataset.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4d1e7fe-a0e5-4556-b2e1-63ae0801b873",
   "metadata": {},
   "source": [
    "## Import packages and functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008b18f-8936-44c1-8b13-1cd191042ad3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import cv2\n",
    "import shutil\n",
    "import random\n",
    "from utils import utils\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd19cafb-be9c-4bf5-8f99-543a9b7a1e55",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "TMP_LABEL = \"/tmp/ls-label.txt\"\n",
    "UTILS_DIR_PATH = \"utils/\"\n",
    "LABELS_INFO = UTILS_DIR_PATH + \"labels.json\"\n",
    "DATASET_PATH = \"dataset/\"\n",
    "DATA_CONFIG_PATH = \"utils/data.yaml\"\n",
    "\n",
    "NB_FRAMES_PER_VIDEO = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a34491c-8138-4c6c-a029-d65394c28274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_dirs():\n",
    "    os.makedirs(DATASET_PATH, exist_ok = True)\n",
    "    os.makedirs(DATASET_PATH + \"labels/train\", exist_ok = True)\n",
    "    os.makedirs(DATASET_PATH + \"labels/test\", exist_ok = True)\n",
    "    os.makedirs(DATASET_PATH + \"labels/val\", exist_ok = True)\n",
    "    os.makedirs(DATASET_PATH + \"images/train\", exist_ok = True)\n",
    "    os.makedirs(DATASET_PATH + \"images/test\", exist_ok = True)\n",
    "    os.makedirs(DATASET_PATH + \"images/val\", exist_ok = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db8b35f-a464-45f3-aea2-4d0285baba27",
   "metadata": {},
   "source": [
    "## Visualize Exampl Traffic Signs.\n",
    "\n",
    "The synthetic data generation algorighm extracts frames from the `utils/video/video1.mp4` file and inserts traffic sign images into those frames\n",
    "\n",
    "The background of traffic sign images is transparent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6b72fd-a952-4b91-b36f-0399065f5c22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "files = [e for e in os.listdir(\"utils/images\") if \"lego\" in e]\n",
    "fig = plt.figure(figsize=(10, 7)) \n",
    "rows, columns = 1, 6\n",
    "for i, file in enumerate(files):\n",
    "    fig.add_subplot(rows, columns, i+1)\n",
    "    image = cv2.imread(\"utils/images/\"+file)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86192be",
   "metadata": {},
   "source": [
    "## Select Some Images for the Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8cfe40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure reproducibility\n",
    "! tar -xzf dataset.tar.gz\n",
    "random.seed(1)\n",
    "\n",
    "val_images_dir = Path(DATASET_PATH) / \"images\" / \"val\"\n",
    "val_labels_dir = Path(DATASET_PATH) / \"labels\" / \"val\"\n",
    "\n",
    "test_images_dir = Path(DATASET_PATH) / \"images\" / \"test\"\n",
    "test_labels_dir = Path(DATASET_PATH) / \"labels\" / \"test\"\n",
    "\n",
    "# Select 6 random validation images and corresponding labels\n",
    "img_files = random.sample([f for f in val_images_dir.iterdir()], 6)\n",
    "label_files = [val_labels_dir / f.name.replace(\"jpg\", \"txt\") for f in img_files]\n",
    "\n",
    "# Clean up test dirs from previous runs\n",
    "!rm -rf dataset/images/test/*\n",
    "!rm -rf dataset/labels/test/*\n",
    "\n",
    "# Move from val to test dir\n",
    "for f in img_files:\n",
    "    shutil.move(f, test_images_dir)\n",
    "for f in label_files:\n",
    "    shutil.move(f, test_labels_dir)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27857b70-535e-4081-bc19-74757eeb073c",
   "metadata": {},
   "source": [
    "## Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad46bc48-dee1-4c3d-8349-12cfda3039b2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_dirs()\n",
    "with open(LABELS_INFO) as f:\n",
    "    label_info = json.load(f)\n",
    "\n",
    "video_path = UTILS_DIR_PATH + \"video/video1.mp4\"\n",
    "random_frames = utils.extract_random_frames(video_path, NB_FRAMES_PER_VIDEO)\n",
    "num_frames = len(random_frames)\n",
    "\n",
    "# Iterate on random frames from the video\n",
    "for i, frame in enumerate(random_frames):\n",
    "    frame_height, frame_width, _ = frame.shape\n",
    "    for label in label_info.keys():\n",
    "        label_id = label_info[label][\"label_id\"]\n",
    "        for traffic_sign_info in label_info[label][\"children\"].values():\n",
    "            # Insert traffic sign onto frame\n",
    "            # All possible traffic signs are stored in the utils folder\n",
    "            image_path = UTILS_DIR_PATH + traffic_sign_info[\"path\"]\n",
    "            bbox_size = (int(traffic_sign_info[\"bbox_w\"]), int(traffic_sign_info[\"bbox_h\"]))\n",
    "            inserted_image = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "            if inserted_image is None:\n",
    "                raise Exception(\"Error: Couldn't load the inserted image file.\")\n",
    "            frame_copy = frame.copy()\n",
    "            frame_copy, coordinates = utils.insert_image(frame_copy, inserted_image, frame_width, frame_height, bbox_size)\n",
    "\n",
    "            # Save labels and images in yolo format\n",
    "            yolo_format = utils.to_yolo_format(frame_width, frame_height, coordinates)\n",
    "            split = utils.determine_split(i, num_frames)\n",
    "            utils.add_to_yolo_dataset(frame_copy, split, label_id, label, yolo_format, DATASET_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46cf7398",
   "metadata": {},
   "source": [
    "### Get Split Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0620921",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -1 dataset/images/train | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b791e683",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -1 dataset/images/val | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55b0e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -1 dataset/images/test | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b1370-dcfe-4ca2-be00-2d7e300461df",
   "metadata": {},
   "source": [
    "## Visualize Some Synthetic Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5626f569-8431-450b-86f3-9533e929d692",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = random.choice([ f for f in os.listdir(\"dataset/images/train\") if any(match_name in f for match_name in [\"SpeedLimit\", \"DangerAhead\"]) ])\n",
    "image = cv2.imread(\"dataset/images/train/\"+file)\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1952f47",
   "metadata": {},
   "source": [
    "## Pack the Extended Dataset\n",
    "\n",
    "Compress the full dataset in a tar.gz file. The training step will use this file to train the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdaf4c2-6337-4018-8a7b-e3e76367592b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "! tar -czf dataset-full.tar.gz dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
