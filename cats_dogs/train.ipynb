{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f0aeee1f050>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "from collection import s3_download_file\n",
    "from preprocessing import preprocess\n",
    "from prediction import predict\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_DATA_FILE = os.getenv(\"S3_DATA_FILE\", \"kagglecatsanddogs_5340.zip\")\n",
    "s3_download_file(S3_DATA_FILE, \".cache/data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -n -q .cache/data.zip -d .cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 corrupted images.\n",
      "Classes: ['Cat', 'Dog']\n",
      "Features first batch size: torch.Size([32, 3, 50, 50])\n",
      "Labels first batch size: torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "# Directory path of your dataset\n",
    "data_dir = '.cache/PetImages'\n",
    "\n",
    "# Preprocess data: clean, resize,\n",
    "# split into test and validation subsets...\n",
    "train_loader, val_loader, dataset = preprocess(data_dir)\n",
    "\n",
    "# Verify the class labels of the dataset\n",
    "print(\"Classes:\", dataset.classes)\n",
    "\n",
    "# Verify sizes\n",
    "for images, labels in train_loader:\n",
    "    print(\"Features first batch size:\", images.size())\n",
    "    print(\"Labels first batch size:\", labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each iteration, the data loader returns a tuple of two batches (images and labels).\n",
    "The images batch contains 32 images.\n",
    "The labels batch contains the corresponding 32 labels for those images.\n",
    "\n",
    "Each image has 50x50 pixels, with 3 color channels (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda:0 for training\n"
     ]
    }
   ],
   "source": [
    "# Define the model (use a pre-trained ResNet and modify the final layer)\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "# Modify final layer to define 2 output classes: Cat and Dog\n",
    "model.fc = nn.Linear(num_features, len(dataset.classes))\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(f\"Using {device} for training\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3, \n",
      " Training Loss: 0.4265\n",
      " Validation Loss: 0.3337, Accuracy: 0.8445\n",
      "Epoch 2/3, \n",
      " Training Loss: 0.2884\n",
      " Validation Loss: 0.3252, Accuracy: 0.8413\n",
      "Epoch 3/3, \n",
      " Training Loss: 0.2316\n",
      " Validation Loss: 0.3019, Accuracy: 0.8795\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}: \\n Training Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels.data)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = correct.double() / len(val_loader.dataset)\n",
    "    print(f' Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cat\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Smoke test the model\n",
    "result = predict(\"test_cat.jpg\", model)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate a random Torch to specify\n",
    "# the inputs dimensions expected by the model\n",
    "first_batch_example = torch.randn(1, 3, 50, 50).to(device)\n",
    "# Export to ONNX\n",
    "torch.onnx.export(model, first_batch_example, \"model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
