{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import models\n",
    "\n",
    "from collection import s3_download_file\n",
    "from preprocessing import delete_corrupted, preprocess\n",
    "from prediction import predict\n",
    "\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_download_file(\"kagglecatsanddogs_5340.zip\", \".cache/data.zip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!unzip -q -n data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleted 0 corrupted images.\n"
     ]
    }
   ],
   "source": [
    "# Directory path of your dataset\n",
    "data_dir = 'PetImages'\n",
    "\n",
    "delete_corrupted(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Cat', 'Dog']\n",
      "torch.Size([32, 3, 50, 50]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, dataset = preprocess(data_dir)\n",
    "\n",
    "# Verify the class labels of the dataset\n",
    "print(dataset.classes)\n",
    "\n",
    "# Verify sizes\n",
    "for images, labels in train_loader:\n",
    "    print(\"Size of first batch\")\n",
    "    print(\"Features size:\", images.size())\n",
    "    print(\"Labels size:\", labels.size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In each iteration, the data loader returns a tuple of two batches (images and labels).\n",
    "The images batch contains 32 images.\n",
    "The labels batch contains the corresponding 32 labels for those images.\n",
    "\n",
    "Each image has 50x50 pixels, with 3 color channels (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, \n",
      " Training Loss: 0.4139\n",
      "Validation Loss: 0.4070, Accuracy: 0.7826\n",
      "Epoch 2/10, \n",
      " Training Loss: 0.2825\n",
      "Validation Loss: 0.3051, Accuracy: 0.8706\n",
      "Epoch 3/10, \n",
      " Training Loss: 0.2249\n",
      "Validation Loss: 0.3125, Accuracy: 0.8704\n",
      "Epoch 4/10, \n",
      " Training Loss: 0.1852\n",
      "Validation Loss: 0.3332, Accuracy: 0.8610\n",
      "Epoch 5/10, \n",
      " Training Loss: 0.1535\n",
      "Validation Loss: 0.3493, Accuracy: 0.8748\n",
      "Epoch 6/10, \n",
      " Training Loss: 0.1294\n",
      "Validation Loss: 0.2810, Accuracy: 0.8881\n",
      "Epoch 7/10, \n",
      " Training Loss: 0.0934\n",
      "Validation Loss: 0.3358, Accuracy: 0.8913\n",
      "Epoch 8/10, \n",
      " Training Loss: 0.0891\n",
      "Validation Loss: 0.4179, Accuracy: 0.8648\n",
      "Epoch 9/10, \n",
      " Training Loss: 0.0676\n",
      "Validation Loss: 0.3852, Accuracy: 0.8746\n",
      "Epoch 10/10, \n",
      " Training Loss: 0.0659\n",
      "Validation Loss: 0.3709, Accuracy: 0.8830\n"
     ]
    }
   ],
   "source": [
    "# Define the model (use a pre-trained ResNet and modify the final layer)\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "# Modify final layer to define 2 output classes: Cat and Dog\n",
    "model.fc = nn.Linear(num_features, 2)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "print(\"Using {device} for training\")\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()  # Zero the parameter gradients\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, \\n Training Loss: {epoch_loss:.4f}')\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * inputs.size(0)\n",
    "\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += torch.sum(preds == labels.data)\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    val_accuracy = correct.double() / len(val_loader.dataset)\n",
    "    print(f' Validation Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Image' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPetImages/Cat/0.jpg\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#image = transform(image).unsqueeze(0)\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m)\n\u001b[1;32m      7\u001b[0m image \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      8\u001b[0m  \u001b[38;5;66;03m# Make prediction\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Image' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# Test with new image\n",
    "from PIL import Image\n",
    "\n",
    "result = predict(\"PetImages/Cat/0.jpg\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first_batch_example = next(iter(val_loader))[0].to(device)\n",
    "first_batch_example = torch.randn(1, 3, 50, 50).to(device)\n",
    "version = datetime.now().strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "torch.onnx.export(model, first_batch_example, f\"cats-vs-dogs/v{version}/model.onnx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
